{"title":"Ubuntu搭建Hadoop&HBase集群","slug":"hadoop-hbase-cluster-on-ubuntu","date":"2018-01-19T05:23:21.000Z","updated":"2018-04-22T07:14:27.882Z","comments":true,"excerpt":"","content":"<h2 id=\"1-环境\"><a href=\"#1-环境\" class=\"headerlink\" title=\"1. 环境:\"></a>1. 环境:</h2><ul>\n<li>3个UbuntuServer 分别在/etc/hosts中配置ip<pre><code>192.168.0.111 master\n192.168.0.112 slave1\n192.168.0.113 slave2\n</code></pre></li>\n<li>三台机器安装的环境<blockquote>\n<p>master: jdk hadoop  hbase zookeeper<br>salve1: jdk hadoop  hbase<br>salve2: jdk hadoop  hbase  </p>\n</blockquote>\n</li>\n</ul>\n<h2 id=\"2-搭建\"><a href=\"#2-搭建\" class=\"headerlink\" title=\"2. 搭建:\"></a>2. 搭建:</h2><ul>\n<li><img src=\"/2018/01/19/hadoop-hbase-cluster-on-ubuntu/2.png\" alt=\"\"><br>准备好这几个项目的包,去对应的官网下载即可  <ul>\n<li>hadoop  </li>\n<li>hbase  </li>\n<li>zookeeper  </li>\n<li>jdk  </li>\n</ul>\n</li>\n<li>解压到你喜欢的位置,我习惯在/usr/local下安装<br>配置Java,HBase,Hadoop的环境变量什么的不解释了<br><img src=\"/2018/01/19/hadoop-hbase-cluster-on-ubuntu/3.png\" alt=\"\"><br>环境变量,对应你的文件目录<br>这里没有配置zookeeper的环境变量,也可以配置  </li>\n<li><p>zookeeper的配置文件<br><img src=\"/2018/01/19/hadoop-hbase-cluster-on-ubuntu/4.png\" alt=\"\"><br>启动zookeeper<br><img src=\"/2018/01/19/hadoop-hbase-cluster-on-ubuntu/5.png\" alt=\"\"><br>可以jps一下<br><img src=\"/2018/01/19/hadoop-hbase-cluster-on-ubuntu/6.png\" alt=\"\"><br>看到这个就是zookeeper的进程了</p>\n</li>\n<li><p>在$HADOOP_CONFIG_HOME是hadoop的配置文件<br>我们需要修改如下几个:<br>1.core-site.xml<br><img src=\"/2018/01/19/hadoop-hbase-cluster-on-ubuntu/7.png\" alt=\"\">  </p>\n<pre><code>&lt;description&gt;标签无所谓的,注意hadoop.tmp.dir指定的文件夹我们要提前建好\n</code></pre><p>2.hadoop-env.sh<br>修改<br><img src=\"/2018/01/19/hadoop-hbase-cluster-on-ubuntu/8.png\" alt=\"\"><br>换成你的jdk位置<br><img src=\"/2018/01/19/hadoop-hbase-cluster-on-ubuntu/9.png\" alt=\"\"><br>3.mapred-site.xml<br><img src=\"/2018/01/19/hadoop-hbase-cluster-on-ubuntu/10.png\" alt=\"\"><br>4.slaves添加从节点的ip</p>\n<pre><code>slave1\nslave2\n</code></pre><p>5.配置主从节点之间所有机器的免密ssh登陆<br>  1).<code>ssh-keygen -t rsa</code>然后回车回车再回车一路确认<br>  2).然后<code>ssh-copy-id -i /root/.ssh/id_rsa.pub master</code><br>  3).然后按照这个步骤将三台机器都配置好,也可以scp复制过去<br>6.<code>cd $HBASE_HOME/conf:</code><br><img src=\"/2018/01/19/hadoop-hbase-cluster-on-ubuntu/12.png\" alt=\"\"><br><img src=\"/2018/01/19/hadoop-hbase-cluster-on-ubuntu/13.png\" alt=\"\"><br>修改上图这三项JAVA_HOME,HBASE_CLASSPATH,HBASE_MANAGES_ZK<br>7.hbase-site.xml<br><img src=\"/2018/01/19/hadoop-hbase-cluster-on-ubuntu/14.png\" alt=\"\"><br>8.regionservers  </p>\n<pre><code>slave1\nslave2\n</code></pre><p>9.将$HADOOP_CONFIG_HOME的core-site.xml和hdfs-site.xml复制一份到$HBASE_HOME/conf</p>\n</li>\n</ul>\n<h2 id=\"3-启动-amp-验证\"><a href=\"#3-启动-amp-验证\" class=\"headerlink\" title=\"3. 启动&amp;验证\"></a>3. 启动&amp;验证</h2><p>然后在master:<br>1.start-all.sh启动hadoop,<br>访问master:50070看到:<br><img src=\"/2018/01/19/hadoop-hbase-cluster-on-ubuntu/16.png\" alt=\"\"><br>访问master:8088:<br><img src=\"/2018/01/19/hadoop-hbase-cluster-on-ubuntu/17.png\" alt=\"\"><br>2.开启zookeeper<br><code>/usr/local/zookeeper/bin/zkServer.sh start</code><br>3.start-hbase.sh<br>访问master:16010<br><img src=\"/2018/01/19/hadoop-hbase-cluster-on-ubuntu/19.png\" alt=\"\"><br>至此基本的的Hadoop,HBase集群就搭建完成了</p>\n","categories":[{"name":"Hadoop","path":"api/categories/Hadoop.json"},{"name":"HBase","path":"api/categories/HBase.json"}],"tags":[{"name":"ForRemember","path":"api/tags/ForRemember.json"}]}